{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numba\n",
    "from tracking.sort import Sort\n",
    "from detection.wrapper import VehicleDetector\n",
    "import json\n",
    "\n",
    "def draw_boxes(img, boxes_xyxy, texts, color, thickness=1):\n",
    "    if texts is not None:\n",
    "        for (x_min, y_min, x_max, y_max), t in zip(boxes_xyxy.astype(np.int), texts):\n",
    "            cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "            cv2.putText(img, str(t), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    else:\n",
    "        for x_min, y_min, x_max, y_max in boxes_xyxy.astype(np.int):\n",
    "            cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "    return img\n",
    "def draw_arrow(img,point,color):\n",
    "    cv2.polylines(img,[np.array(point)],True,color,thickness=2)\n",
    "    p0_x = point[-2][0]\n",
    "    p0_y = point[-2][1]\n",
    "    p1_x = point[-1][0]\n",
    "    p1_y = point[-1][1]\n",
    "    cv2.arrowedLine(img, (int(p0_x), int(p0_y)), (int(p1_x), int(p1_y)), (0,255,0),5)\n",
    "    return img\n",
    "\n",
    "def draw_one_boxes(img, bbox, text, color, thickness=1):\n",
    "    (x_min, y_min,x_max, y_max) = bbox\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    cv2.putText(img, \"ID\" + str(text), (x_min, y_min - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"counting/zones-movement_paths/cam_01.json\",\"r\") as file :\n",
    "    data = json.load(file)\n",
    "    # get param image\n",
    "    path_image = data[\"imagePath\"]\n",
    "    width = data[\"imageWidth\"]\n",
    "    height = data[\"imageHeight\"]\n",
    "    # get ROI\n",
    "    zone = data[\"shapes\"][0][\"points\"]\n",
    "ROI = [[int(x),int(y)] for x,y in zone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movement_1 \n",
    "tracklets_1 =  [[347, 213],[338, 230],[329, 251],[320, 271],[309, 294],[300, 315],[291, 336],\n",
    " [283, 355],[276, 373],[265, 393],[255, 417],[249, 434],[244, 451],[232, 467],[225, 485]]\n",
    "# movement_2\n",
    "tracklets_2 = [[832, 465],[827, 451],[820, 434],[812, 415],[803, 391],[797, 374],[789, 359],[786, 341],\n",
    "                [777, 321],[770, 302],[764, 287],[756, 271],[751, 256],[744, 244],[739, 234]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from counting.hausdorff_dist import hausdorff_distance\n",
    "\n",
    "def check_bbox_inside_with_roi(bbox, mask):\n",
    "    #check if four point of bbox all in roi area\n",
    "    is_inside = True\n",
    "\n",
    "    x_tl = bbox[1]\n",
    "    y_tl = bbox[2]\n",
    "    x_br = bbox[3]\n",
    "    y_br = bbox[4]\n",
    "\n",
    "    for x in [x_tl, x_br]:\n",
    "        if x <= 0 or x >= mask.shape[1]:\n",
    "            return False\n",
    "\n",
    "    for y in [y_tl, y_br]:\n",
    "        if y <= 0 or y >= mask.shape[0]:\n",
    "            return False\n",
    "\n",
    "    vertexs = [[x_tl, y_tl], [x_tl, y_br], [x_br, y_tl], [x_br, y_br]]\n",
    "    for v in vertexs:\n",
    "        (g, b, r) = mask[v[1], v[0]]\n",
    "        if (g, b, r) < (128, 128, 128):\n",
    "            is_inside = False\n",
    "            return is_inside\n",
    "\n",
    "    return is_inside\n",
    "\n",
    "def check_tracks_with_roi(tracks, mask):\n",
    "    tracks_end_in_roi = []\n",
    "    tracks_start_in_roi = []\n",
    "    tracks_too_short = []\n",
    "\n",
    "    for trackid, track in tracks.items():\n",
    "        start_bbox = track['bbox'][0]\n",
    "        end_bbox = track['bbox'][-1]\n",
    "\n",
    "        if check_bbox_inside_with_roi(start_bbox, mask) == True:\n",
    "            if track['startframe'] > 3:\n",
    "                tracks_start_in_roi.append(trackid)\n",
    "\n",
    "        if check_bbox_inside_with_roi(end_bbox, mask) == True:\n",
    "            tracks_end_in_roi.append(trackid)\n",
    "\n",
    "        if track['endframe'] - track['startframe'] < 10:\n",
    "            if trackid not in tracks_start_in_roi:\n",
    "                tracks_too_short.append(trackid)\n",
    "    return tracks_end_in_roi, tracks_start_in_roi, tracks_too_short\n",
    "\n",
    "\n",
    "def check_bbox_overlap_with_roi(bbox, mask):\n",
    "    is_overlap = False\n",
    "    if bbox[1] >= mask.shape[1] or bbox[2] >= mask.shape[0] \\\n",
    "            or bbox[3] < 0 or bbox[4] < 0:\n",
    "        return is_overlap\n",
    "\n",
    "    x_tl = bbox[1] if bbox[1] > 0 else 0\n",
    "    y_tl = bbox[2] if bbox[2] > 0 else 0\n",
    "    x_br = bbox[3] if bbox[3] < mask.shape[1] else mask.shape[1] - 1\n",
    "    y_br = bbox[4] if bbox[4] < mask.shape[0] else mask.shape[0] - 1\n",
    "    vertexs = [[x_tl, y_tl], [x_tl, y_br], [x_br, y_tl], [x_br, y_br]]\n",
    "    for v in vertexs:\n",
    "        (g, b, r) = mask[v[1], v[0]]\n",
    "        if (g, b, r) > (128, 128, 128):\n",
    "            is_overlap = True\n",
    "            return is_overlap\n",
    "\n",
    "    return is_overlap\n",
    "\n",
    "def is_same_direction(traj1, traj2, angle_thr):\n",
    "    vec1 = np.array([traj1[-1][0] - traj1[0][0], traj1[-1][1] - traj1[0][1]])\n",
    "    vec2 = np.array([traj2[-1][0] - traj2[0][0], traj2[-1][1] - traj2[0][1]])\n",
    "    L1 = np.sqrt(vec1.dot(vec1))\n",
    "    L2 = np.sqrt(vec2.dot(vec2))\n",
    "    if L1 == 0 or L2 == 0:\n",
    "        return False\n",
    "    cos = vec1.dot(vec2)/(L1*L2)\n",
    "    angle = np.arccos(cos) * 360/(2*np.pi)\n",
    "    if angle < angle_thr:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def calc_angle(vec1, vec2):\n",
    "    vec1 = np.array([traj1[-1][0] - traj1[-5][0], traj1[-1][1] - traj1[-5][1]])\n",
    "    vec2 = np.array([traj2[-1][0] - traj2[-5][0], traj2[-1][1] - traj2[-5][1]])\n",
    "    L1 = np.sqrt(vec1.dot(vec1))\n",
    "    L2 = np.sqrt(vec2.dot(vec2))\n",
    "    if L1 == 0 or L2 == 0:\n",
    "        return 90\n",
    "    cos = vec1.dot(vec2)/(L1*L2)\n",
    "    if cos > 1:\n",
    "        return 90\n",
    "    angle = np.arccos(cos) * 360/(2*np.pi)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "cam_conf = \"counting/cam_configs/cam-1.json\"\n",
    "tipical_trajs = {}\n",
    "with open(cam_conf, 'r') as fc:\n",
    "    movements = json.load(fc)\n",
    "    for movement_id, movement_info in movements.items():\n",
    "        tracklets = movement_info['tracklets']\n",
    "        tipical_trajs[movement_id] = tracklets\n",
    "#load mask image\n",
    "cam_mask = os.path.join('counting/mask', \"cam_01.png\")\n",
    "mask = cv2.imread(cam_mask)\n",
    "h, w, c = mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tracking\n",
    "def get_track(tracks,frameID):\n",
    "    global trackings\n",
    "    if len(tracks) > 0 :\n",
    "        for idx in range(len(tracks)):\n",
    "            xmin, ymin, xmax, ymax = tracks[idx, :4]\n",
    "            xmin, ymin, xmax, ymax = int(xmin),int(ymin),int(xmax),int(ymax)\n",
    "            trackID = tracks[idx, 4].astype(int)\n",
    "            cx = int((xmax-xmin)/2)\n",
    "            cy = int((ymax-ymin)/2)\n",
    "            if trackID not in trackings :\n",
    "                trackings[trackID] = {'startframe' : frameID,\n",
    "                                     'endframe': frameID,\n",
    "                                     'bbox' : [[frameID, xmin, ymin, xmax, ymax, 2]],\n",
    "                                      'tracklet' : [[cx, cy]]\n",
    "                                               \n",
    "                                     }# fixed classes\n",
    "            else :\n",
    "                trackings[trackID]['endframe'] = frameID\n",
    "                trackings[trackID][\"bbox\"].append([frameID, xmin, ymin, xmax, ymax, 2])\n",
    "                trackings[trackID][\"tracklet\"].append([cx, cy])\n",
    "#     return trackings\n",
    "# PARAM\n",
    "dist_thr = 300\n",
    "angle_thr = 30\n",
    "min_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n",
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11177MB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = VehicleDetector(device='0')  # select gpu:0\n",
    "tracker = Sort(max_age=15)\n",
    "\n",
    "test_video = \"/media/thorpham/PROJECT/AIC_2020_Challenge_Track-1/thor/data/videos/cam_01.mp4\"\n",
    "vs = cv2.VideoCapture(test_video)\n",
    "framID = 0\n",
    "trackings = {}\n",
    "while True:\n",
    "    ret, frame = vs.read()\n",
    "    imshow = frame.copy()\n",
    "    if ret:\n",
    "        framID += 1\n",
    "        cv2.polylines(imshow,[np.array(ROI)],True,(0,0,255),thickness=4)\n",
    "        start = time.time()\n",
    "        detections = detector.detect(frame)\n",
    "        detect_timestamp = time.time()\n",
    "\n",
    "        detected_boxes = []\n",
    "        for det in detections:\n",
    "            box_xyxy = det[:4]\n",
    "            detected_boxes.append(box_xyxy)\n",
    "        detected_boxes = np.array(detected_boxes)\n",
    "        tracks = tracker.update(detected_boxes)\n",
    "        track_timestamp = time.time()\n",
    "        get_track(tracks,framID)\n",
    "#         print(trackings)\n",
    "        ##split tracklets\n",
    "        tracks_end_in_roi, tracks_start_in_roi, tracks_too_short = check_tracks_with_roi(trackings, mask)\n",
    "        trackids = sorted([k for k in trackings.keys()])\n",
    "        for trackid in trackids:\n",
    "            if len(trackings[trackid]['tracklet']) < min_length:\n",
    "                continue\n",
    "            track_traj = trackings[trackid]['tracklet']\n",
    "            #calc hausdorff dist with tipical trajs, assign the movement with the min dist\n",
    "            all_dists_dict = {k: float('inf') for k in tipical_trajs}\n",
    "            for m_id, m_t in tipical_trajs.items():\n",
    "                for t in m_t:\n",
    "                    tmp_dist = hausdorff_distance(np.array(track_traj), np.array(t), distance='euclidean')\n",
    "                    if tmp_dist < all_dists_dict[m_id]:\n",
    "                        all_dists_dict[m_id] = tmp_dist\n",
    "\n",
    "            #check direction\n",
    "            all_dists = sorted(all_dists_dict.items(), key=lambda k: k[1])\n",
    "            min_idx, min_dist = None, dist_thr\n",
    "            for i in range(0, len(all_dists)):\n",
    "                m_id = all_dists[i][0]\n",
    "                m_dist = all_dists[i][1]\n",
    "                if m_dist >= dist_thr: #if min dist > dist_thr, will not assign to any movement\n",
    "                    break\n",
    "                else:\n",
    "                    if is_same_direction(track_traj, tipical_trajs[m_id][0], angle_thr): #check direction\n",
    "                        min_idx = m_id\n",
    "                        min_dist = m_dist\n",
    "                        break #if match, end\n",
    "                    else:\n",
    "                        continue #direction not matched, find next m_id\n",
    "                        \n",
    "                        \n",
    "        track_h = trackings[trackid]['bbox'][0][4] - trackings[trackid]['bbox'][0][2]\n",
    "        if abs(track_traj[-1][1] - track_traj[0][1]) < track_h:\n",
    "            continue\n",
    "#         mv_idx = min_idx.split('_')[1]\n",
    "        #get last frameid in roi\n",
    "        bboxes = trackings[trackid]['bbox']\n",
    "        bboxes.sort(key=lambda x: x[0])\n",
    "\n",
    "        dst_frame = bboxes[0][0]\n",
    "        last_bbox = bboxes[-1]\n",
    "        if check_bbox_overlap_with_roi(last_bbox, mask) == True:\n",
    "            draw_one_boxes(imshow,last_bbox[1:5],str(trackid), (255,0,255), thickness=3)\n",
    "            dst_frame = last_bbox[0]\n",
    "        else:\n",
    "            for i in range(len(bboxes) - 2, 0, -1):\n",
    "                bbox = bboxes[i]\n",
    "                if check_bbox_overlap_with_roi(bbox, mask) == True:\n",
    "                    dst_frame = bbox[0]\n",
    "                    draw_one_boxes(imshow,last_bbox[1:5],str(trackid), (255,0,255), thickness=3)\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "#         print(\"frame {}: detection time: {} s, trackin time: {} s\".format(tracker.frame_count, detect_timestamp - start,\n",
    "#                                                                           track_timestamp - detect_timestamp))\n",
    "\n",
    "        # frame = draw_boxes(frame, detected_boxes, color=[0, 255, 0])\n",
    "        frame = draw_boxes(imshow, tracks[:, :4], tracks[:, 4].astype(int), color=[0, 255, 255])\n",
    "        frame = draw_arrow(imshow,tracklets_1,(255,0,0))\n",
    "        frame = draw_arrow(imshow,tracklets_2[::-1],(255,255,0))\n",
    "        # print(tracks)\n",
    "        cv2.imshow(\"track\", imshow)\n",
    "\n",
    "        # fix frame rate at 30 fps\n",
    "        stop_time = time.time()\n",
    "        wait_time = int(33.33 - (stop_time - start)*1000)\n",
    "#         cv2.waitKey(max(wait_time, 1))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[191, 176, 211, 212]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_bbox[1:5]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas>=1.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ocr': conda)",
   "language": "python",
   "name": "python37764bitocrcondaa94ca99b6aaa446a9351ff64ec4b0cfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
